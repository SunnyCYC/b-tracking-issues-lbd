# What Can Go Wrong When Conducting Beat Tracking Experiments

This is the repo for the ISMIR late-breaking demo paper titled
"*What Can Go Wrong When Conducting Beat Tracking Experiments*".

## Abstract
Automated beat tracking is a central task in music information retrieval (MIR) and aims to find time positions that humans would tap along when listening to music. In a previous contribution [1], we built upon an existing beat tracking system and evaluated the results on annotated datasets of Western classical music. In our experiments, we obtained poor evaluation results which we first attributed to the complexity of the music. We later discovered that many of the poor results can be traced back to technical issues in the processing pipeline and inaccurate beat annotations. In this contribution, we report on some of these issues and make suggestions regarding visualization and sonification to better understand the data and results.

## Annotation Issues in ASAP dataset [2]

### Shifted Beat Annotations

### Missing Beat Annotations
### Unreasonably Short Inter-Beat Intervals





## Reference
[1] C. Chiu, M. Muller, M. E. P. Davies, A. W. Su, and Y. Yang, “Local periodicity-based beat tracking for expressive classical piano music,” IEEE/ACM Transactions on Audio, Speech, and Language Processing, vol. 31, pp. 2824–2835, 2023
[2] F. Foscarin, A. McLeod, P. Rigaux, F. Jacquemard, and M. Sakai, “ASAP: a dataset of aligned scores and performances for piano transcription,” in Proceedings of the International Society for Music Information Retrieval Conference (ISMIR), 2020, pp. 534–541.
[3] S. Böck, F. Korzeniowski, J. Schlüter, F. Krebs, and G.Widmer, “madmom: A new Python audio and music signal processing library,” in Proceedings of the ACM International Conference on Multimedia (ACM-MM), pp. 1174–1178.
[4] C. S. Sapp, “Hybrid numeric/rank similarity metrics,” in Proceedings of the International Society for Music Information Retrieval Conference (ISMIR), 2008, pp. 501–506.
